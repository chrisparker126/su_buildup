{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/su_buildup/su_buildup', '', '/home/ubuntu/src/cntk/bindings/python', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python36.zip', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/lib-dynload', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/extensions', '/home/ubuntu/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "up1 = os.path.abspath('..') \n",
    "sys.path.insert(0, up1)\n",
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import cv2, numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, RepeatVector\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import regularizers\n",
    "from keras.callbacks import History \n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras_data_generator.ucf101_datagenerator.generator_class import DataGenerator\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The VGG 16 model of spatial training\n",
    "\n",
    "    So the idea here is that we're building a VGG 16 model without the top included. Essentially we want all the feature\n",
    "    learning component of the model without the fully connected layer and input layer. We will also freeze VGG 16 FL layers \n",
    "    as we simply want it to learn how to classify based on the input from the sport action recognition layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = { 'data_dir' : \"/data\",\n",
    "          'dim': (224,224),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 101,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVggModel(LR,l1v,drp,printmod=1):\n",
    "\n",
    "    base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "    x = base_model.get_layer('block5_pool').output   # collect outputs from hidden layer, Block 5\n",
    "    # stitch layers to the VGG16 layers\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "\n",
    "    predictions = Dense(101, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # freeze original VGG16 layers\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if 'block1' in layer.name or 'block2' in layer.name or 'block3' in layer.name or \\\n",
    "        'block4' in layer.name or 'block5' in layer.name:\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "            \n",
    "    mypotim = SGD(lr=LR, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=mypotim,\n",
    "                  metrics=['accuracy'])\n",
    "    if (printmod==1 ):\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getData(listPath):\n",
    "# load Id list and labels \n",
    "\n",
    "    train_list = list()\n",
    "\n",
    "    with open(listPath, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        train_list = list(reader)\n",
    "\n",
    "        labels = [int(label[0].split(' ')[1]) for label in train_list ]\n",
    "    IDs = [label[0].split(' ')[0] for label in train_list ]\n",
    "    # IDs\n",
    "    IDs = [id.split('/')[1].rstrip('.avi') for id in IDs ]\n",
    "\n",
    "    labels = dict(zip(IDs, labels))\n",
    "    return (IDs, labels)\n",
    "\n",
    "id_labels_train = getData('../keras_data_generator/ucf101_splits/trainlist01.txt')\n",
    "id_labels_test = getData('../keras_data_generator/ucf101_splits/trainlist02.txt')\n",
    "\n",
    "training_generator = DataGenerator(*id_labels_train, **params)\n",
    "validation_generator = DataGenerator(*id_labels_test, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "def get_callbacks(filepath, patience=10):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "file_path = \".model_weights.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 4s 0us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               25957     \n",
      "=================================================================\n",
      "Total params: 21,163,429\n",
      "Trainable params: 6,448,741\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=getVggModel(1e-4,1e-1,0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-20ae3a9b5f80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train model on dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m mod1 = model.fit_generator(generator=training_generator,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "mod1 = model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=2, epochs=10,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A better Image  Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10243 images belonging to 101 classes.\n",
      "Found 10242 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/data/sym_datasets/jpegs_256_1_train/',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        follow_links=True\n",
    "        )\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/data/sym_datasets/jpegs_256_1_test/',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        follow_links=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 240s 1s/step - loss: 4.5776 - acc: 0.0307 - val_loss: 4.4894 - val_acc: 0.0319\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 184s 1s/step - loss: 4.4401 - acc: 0.0520 - val_loss: 4.3637 - val_acc: 0.0637\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 184s 1s/step - loss: 4.3238 - acc: 0.0714 - val_loss: 4.2391 - val_acc: 0.0763\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 184s 1s/step - loss: 4.2032 - acc: 0.0890 - val_loss: 4.1304 - val_acc: 0.1109\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 184s 1s/step - loss: 4.0904 - acc: 0.1131 - val_loss: 3.9908 - val_acc: 0.1261\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 184s 1s/step - loss: 3.9752 - acc: 0.1428 - val_loss: 3.8817 - val_acc: 0.1545\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 184s 1s/step - loss: 3.8563 - acc: 0.1652 - val_loss: 3.7612 - val_acc: 0.2160\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 184s 1s/step - loss: 3.7548 - acc: 0.1982 - val_loss: 3.6569 - val_acc: 0.2326\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 184s 1s/step - loss: 3.6495 - acc: 0.2269 - val_loss: 3.5418 - val_acc: 0.2606\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 184s 1s/step - loss: 3.5453 - acc: 0.2381 - val_loss: 3.4427 - val_acc: 0.2641\n"
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "mod1 = model.fit_generator(generator=train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=2, epochs=10,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "160/161 [============================>.] - ETA: 0s - loss: 3.4355 - acc: 0.2686Epoch 1/20\n",
      "161/161 [==============================] - 186s 1s/step - loss: 3.4358 - acc: 0.2681 - val_loss: 3.3430 - val_acc: 0.2872\n",
      "Epoch 2/20\n",
      "161/161 [==============================] - 184s 1s/step - loss: 3.3536 - acc: 0.2906 - val_loss: 3.2519 - val_acc: 0.2885\n",
      "Epoch 3/20\n",
      "161/161 [==============================] - 183s 1s/step - loss: 3.2703 - acc: 0.3021 - val_loss: 3.1602 - val_acc: 0.3187\n",
      "Epoch 4/20\n",
      "161/161 [==============================] - 184s 1s/step - loss: 3.1852 - acc: 0.3219 - val_loss: 3.0715 - val_acc: 0.3389\n",
      "Epoch 5/20\n",
      "161/161 [==============================] - 184s 1s/step - loss: 3.0936 - acc: 0.3433 - val_loss: 2.9841 - val_acc: 0.3588\n",
      "Epoch 6/20\n",
      "161/161 [==============================] - 181s 1s/step - loss: 3.0171 - acc: 0.3531 - val_loss: 2.9043 - val_acc: 0.3953\n",
      "Epoch 7/20\n",
      "161/161 [==============================] - 181s 1s/step - loss: 2.9391 - acc: 0.3733 - val_loss: 2.8273 - val_acc: 0.4068\n",
      "Epoch 8/20\n",
      "161/161 [==============================] - 181s 1s/step - loss: 2.8804 - acc: 0.3861 - val_loss: 2.7595 - val_acc: 0.4056\n",
      "Epoch 9/20\n",
      "161/161 [==============================] - 181s 1s/step - loss: 2.8041 - acc: 0.4009 - val_loss: 2.6870 - val_acc: 0.4211\n",
      "Epoch 10/20\n",
      "161/161 [==============================] - 182s 1s/step - loss: 2.7316 - acc: 0.4183 - val_loss: 2.6250 - val_acc: 0.4535\n",
      "Epoch 11/20\n",
      "161/161 [==============================] - 183s 1s/step - loss: 2.6770 - acc: 0.4210 - val_loss: 2.5609 - val_acc: 0.4631\n",
      "Epoch 12/20\n",
      "161/161 [==============================] - 181s 1s/step - loss: 2.6025 - acc: 0.4450 - val_loss: 2.5117 - val_acc: 0.4646\n",
      "Epoch 13/20\n",
      "161/161 [==============================] - 180s 1s/step - loss: 2.5562 - acc: 0.4509 - val_loss: 2.4508 - val_acc: 0.4646\n",
      "Epoch 14/20\n",
      "161/161 [==============================] - 180s 1s/step - loss: 2.4968 - acc: 0.4642 - val_loss: 2.4012 - val_acc: 0.4786\n",
      "Epoch 15/20\n",
      "161/161 [==============================] - 180s 1s/step - loss: 2.4490 - acc: 0.4723 - val_loss: 2.3444 - val_acc: 0.4977\n",
      "Epoch 16/20\n",
      "161/161 [==============================] - 181s 1s/step - loss: 2.4014 - acc: 0.4834 - val_loss: 2.2993 - val_acc: 0.4830\n",
      "Epoch 17/20\n",
      "161/161 [==============================] - 183s 1s/step - loss: 2.3558 - acc: 0.4895 - val_loss: 2.2584 - val_acc: 0.5047\n",
      "Epoch 18/20\n",
      "161/161 [==============================] - 183s 1s/step - loss: 2.3083 - acc: 0.4975 - val_loss: 2.2276 - val_acc: 0.4993\n",
      "Epoch 19/20\n",
      "161/161 [==============================] - 183s 1s/step - loss: 2.2731 - acc: 0.5053 - val_loss: 2.1688 - val_acc: 0.5266\n",
      "Epoch 20/20\n",
      "161/161 [==============================] - 184s 1s/step - loss: 2.2289 - acc: 0.5147 - val_loss: 2.1240 - val_acc: 0.5344\n"
     ]
    }
   ],
   "source": [
    "mod1 = model.fit_generator(generator=train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=2, epochs=20,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d7f08b7a3e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "mod1['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
