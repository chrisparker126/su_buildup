{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/su_buildup/su_buildup', '', '/home/ubuntu/src/cntk/bindings/python', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python36.zip', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/lib-dynload', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/extensions', '/home/ubuntu/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "up1 = os.path.abspath('..') \n",
    "sys.path.insert(0, up1)\n",
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import cv2, numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, RepeatVector\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import regularizers\n",
    "from keras.callbacks import History \n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras_data_generator.ucf101_datagenerator.generator_class import DataGenerator\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The VGG 16 model of spatial training\n",
    "\n",
    "    So the idea here is that we're building a VGG 16 model without the top included. Essentially we want all the feature\n",
    "    learning component of the model without the fully connected layer and input layer. We will also freeze VGG 16 FL layers \n",
    "    as we simply want it to learn how to classify based on the input from the sport action recognition layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = { 'data_dir' : \"/data\",\n",
    "          'dim': (224,224),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 101,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVggModel(LR,l1v,drp,printmod=1):\n",
    "\n",
    "    base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "    x = base_model.get_layer('block5_pool').output   # collect outputs from hidden layer, Block 5\n",
    "    # stitch layers to the VGG16 layers\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "\n",
    "    predictions = Dense(101, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # freeze original VGG16 layers\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if 'block1' in layer.name or 'block2' in layer.name or 'block3' in layer.name or \\\n",
    "        'block4' in layer.name or 'block5' in layer.name:\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "            \n",
    "    mypotim = SGD(lr=LR, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=mypotim,\n",
    "                  metrics=['accuracy'])\n",
    "    if (printmod==1 ):\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getData(listPath):\n",
    "# load Id list and labels \n",
    "\n",
    "    train_list = list()\n",
    "\n",
    "    with open(listPath, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        train_list = list(reader)\n",
    "\n",
    "        labels = [int(label[0].split(' ')[1]) for label in train_list ]\n",
    "    IDs = [label[0].split(' ')[0] for label in train_list ]\n",
    "    # IDs\n",
    "    IDs = [id.split('/')[1].rstrip('.avi') for id in IDs ]\n",
    "\n",
    "    labels = dict(zip(IDs, labels))\n",
    "    return (IDs, labels)\n",
    "\n",
    "id_labels_train = getData('../keras_data_generator/ucf101_splits/trainlist01.txt')\n",
    "id_labels_test = getData('../keras_data_generator/ucf101_splits/trainlist02.txt')\n",
    "\n",
    "training_generator = DataGenerator(*id_labels_train, **params)\n",
    "validation_generator = DataGenerator(*id_labels_test, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "def get_callbacks(filepath, patience=10):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "file_path = \".model_weights.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 5s 0us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               25957     \n",
      "=================================================================\n",
      "Total params: 21,163,429\n",
      "Trainable params: 6,448,741\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=getVggModel(1e-4,1e-1,0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-20ae3a9b5f80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train model on dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m mod1 = model.fit_generator(generator=training_generator,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "mod1 = model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=2, epochs=10,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A better Image  Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "def get_callbacks(filepath):\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [msave]\n",
    "file_path = \".model_weights.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10243 images belonging to 101 classes.\n",
      "Found 60945 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/data/sym_datasets/jpegs_256_1_train/',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        follow_links=True\n",
    "        )\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/data/sym_datasets/jpegs_256_1_test_15_frames/',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        follow_links=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/40\n",
      "161/161 [==============================] - 284s 2s/step - loss: 4.5749 - acc: 0.0336 - val_loss: 4.4838 - val_acc: 0.0525\n",
      "Epoch 2/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 4.4447 - acc: 0.0610 - val_loss: 4.3717 - val_acc: 0.0686\n",
      "Epoch 3/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 4.3315 - acc: 0.0779 - val_loss: 4.2468 - val_acc: 0.0941\n",
      "Epoch 4/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 4.2108 - acc: 0.0963 - val_loss: 4.1257 - val_acc: 0.1062\n",
      "Epoch 5/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 4.0982 - acc: 0.1174 - val_loss: 4.0080 - val_acc: 0.1457\n",
      "Epoch 6/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 3.9774 - acc: 0.1431 - val_loss: 3.8764 - val_acc: 0.1734\n",
      "Epoch 7/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 3.8627 - acc: 0.1702 - val_loss: 3.7582 - val_acc: 0.1815\n",
      "Epoch 8/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 3.7553 - acc: 0.1895 - val_loss: 3.6453 - val_acc: 0.2163\n",
      "Epoch 9/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 3.6440 - acc: 0.2144 - val_loss: 3.5337 - val_acc: 0.2477\n",
      "Epoch 10/40\n",
      "161/161 [==============================] - 191s 1s/step - loss: 3.5441 - acc: 0.2439 - val_loss: 3.4319 - val_acc: 0.2512\n",
      "Epoch 11/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 3.4502 - acc: 0.2573 - val_loss: 3.3257 - val_acc: 0.2827\n",
      "Epoch 12/40\n",
      "161/161 [==============================] - 191s 1s/step - loss: 3.3492 - acc: 0.2787 - val_loss: 3.2315 - val_acc: 0.2995\n",
      "Epoch 13/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 3.2590 - acc: 0.3002 - val_loss: 3.1583 - val_acc: 0.3091\n",
      "Epoch 14/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 3.1768 - acc: 0.3176 - val_loss: 3.0605 - val_acc: 0.3225\n",
      "Epoch 15/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 3.0888 - acc: 0.3290 - val_loss: 2.9757 - val_acc: 0.3574\n",
      "Epoch 16/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 3.0105 - acc: 0.3525 - val_loss: 2.8934 - val_acc: 0.3573\n",
      "Epoch 17/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.9467 - acc: 0.3620 - val_loss: 2.8142 - val_acc: 0.3915\n",
      "Epoch 18/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.8629 - acc: 0.3763 - val_loss: 2.7525 - val_acc: 0.3926\n",
      "Epoch 19/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.7983 - acc: 0.3900 - val_loss: 2.6783 - val_acc: 0.4066\n",
      "Epoch 20/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.7331 - acc: 0.4084 - val_loss: 2.6133 - val_acc: 0.4295\n",
      "Epoch 21/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.6726 - acc: 0.4244 - val_loss: 2.5547 - val_acc: 0.4466\n",
      "Epoch 22/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.6092 - acc: 0.4340 - val_loss: 2.4940 - val_acc: 0.4476\n",
      "Epoch 23/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.5491 - acc: 0.4501 - val_loss: 2.4434 - val_acc: 0.4754\n",
      "Epoch 24/40\n",
      "161/161 [==============================] - 191s 1s/step - loss: 2.4993 - acc: 0.4590 - val_loss: 2.3917 - val_acc: 0.4757\n",
      "Epoch 25/40\n",
      "161/161 [==============================] - 191s 1s/step - loss: 2.4474 - acc: 0.4722 - val_loss: 2.3374 - val_acc: 0.4858\n",
      "Epoch 26/40\n",
      "161/161 [==============================] - 191s 1s/step - loss: 2.3987 - acc: 0.4812 - val_loss: 2.2888 - val_acc: 0.4918\n",
      "Epoch 27/40\n",
      "161/161 [==============================] - 191s 1s/step - loss: 2.3442 - acc: 0.4902 - val_loss: 2.2443 - val_acc: 0.5004\n",
      "Epoch 28/40\n",
      "161/161 [==============================] - 191s 1s/step - loss: 2.3053 - acc: 0.4976 - val_loss: 2.2040 - val_acc: 0.5138\n",
      "Epoch 29/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.2713 - acc: 0.5061 - val_loss: 2.1571 - val_acc: 0.5240\n",
      "Epoch 30/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.2163 - acc: 0.5172 - val_loss: 2.1195 - val_acc: 0.5217\n",
      "Epoch 31/40\n",
      "161/161 [==============================] - 191s 1s/step - loss: 2.1825 - acc: 0.5226 - val_loss: 2.0762 - val_acc: 0.5429\n",
      "Epoch 32/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.1502 - acc: 0.5272 - val_loss: 2.0431 - val_acc: 0.5447\n",
      "Epoch 33/40\n",
      "161/161 [==============================] - 191s 1s/step - loss: 2.1103 - acc: 0.5375 - val_loss: 2.0104 - val_acc: 0.5462\n",
      "Epoch 34/40\n",
      "161/161 [==============================] - 191s 1s/step - loss: 2.0876 - acc: 0.5420 - val_loss: 1.9734 - val_acc: 0.5547\n",
      "Epoch 35/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.0502 - acc: 0.5478 - val_loss: 1.9486 - val_acc: 0.5580\n",
      "Epoch 36/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 2.0090 - acc: 0.5565 - val_loss: 1.9138 - val_acc: 0.5630\n",
      "Epoch 37/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 1.9777 - acc: 0.5636 - val_loss: 1.8826 - val_acc: 0.5696\n",
      "Epoch 38/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 1.9488 - acc: 0.5688 - val_loss: 1.8880 - val_acc: 0.5558\n",
      "Epoch 39/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 1.9073 - acc: 0.5801 - val_loss: 1.8270 - val_acc: 0.5880\n",
      "Epoch 40/40\n",
      "161/161 [==============================] - 192s 1s/step - loss: 1.8831 - acc: 0.5862 - val_loss: 1.8114 - val_acc: 0.5785\n"
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "mod1 = model.fit_generator(generator=train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=2, epochs=40,\n",
    "                    verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.53045807321348, 0.3975387644612258]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator=validation_generator,  use_multiprocessing=True,\n",
    "                    workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [3.343011096268281,\n",
       "  3.2519057419495154,\n",
       "  3.1602119922731053,\n",
       "  3.0715269259330094,\n",
       "  2.984059824093411,\n",
       "  2.9042599307818002,\n",
       "  2.8272782371184295,\n",
       "  2.7594881238846125,\n",
       "  2.6870321712557215,\n",
       "  2.6249798047219,\n",
       "  2.5609259004356386,\n",
       "  2.5117046754124153,\n",
       "  2.450807295607254,\n",
       "  2.4011883640680387,\n",
       "  2.3443527073628316,\n",
       "  2.2992742247843134,\n",
       "  2.258430324618506,\n",
       "  2.22763620855007,\n",
       "  2.168829554204153,\n",
       "  2.1239691087683297],\n",
       " 'val_acc': [0.28724858426088656,\n",
       "  0.2885178676039836,\n",
       "  0.3186877562975981,\n",
       "  0.3388986526069127,\n",
       "  0.3588166373755126,\n",
       "  0.3953329427846124,\n",
       "  0.40675649287248583,\n",
       "  0.405584846709627,\n",
       "  0.42110915836750634,\n",
       "  0.4535247022066003,\n",
       "  0.46309314586994726,\n",
       "  0.4645577035735208,\n",
       "  0.4645577035735208,\n",
       "  0.4786174575278266,\n",
       "  0.4976567076742824,\n",
       "  0.48301113063854717,\n",
       "  0.5046865846514352,\n",
       "  0.49931653973833234,\n",
       "  0.5265573130247998,\n",
       "  0.5343682874438587],\n",
       " 'loss': [3.4413220879622624,\n",
       "  3.356238791501046,\n",
       "  3.264282291130804,\n",
       "  3.1841102130103716,\n",
       "  3.0996784430677673,\n",
       "  3.019817024542114,\n",
       "  2.9449684487927255,\n",
       "  2.8749370944577946,\n",
       "  2.8014165363797776,\n",
       "  2.7283878962555796,\n",
       "  2.6750152300754864,\n",
       "  2.6106948236533234,\n",
       "  2.555067703754865,\n",
       "  2.501634260098194,\n",
       "  2.451970367881803,\n",
       "  2.401332464951807,\n",
       "  2.354086865417941,\n",
       "  2.311455035493626,\n",
       "  2.2712510850156504,\n",
       "  2.227741054895973],\n",
       " 'acc': [0.2657424582699995,\n",
       "  0.2883920726407893,\n",
       "  0.30391486869081324,\n",
       "  0.32383090891340427,\n",
       "  0.33945133261739724,\n",
       "  0.3551693839695402,\n",
       "  0.37157082886455184,\n",
       "  0.38836278434052524,\n",
       "  0.40124963389922896,\n",
       "  0.41882261056622105,\n",
       "  0.42155618471441986,\n",
       "  0.4417651078785512,\n",
       "  0.4516255003446063,\n",
       "  0.4630479351810607,\n",
       "  0.4691984770086889,\n",
       "  0.4843307624748416,\n",
       "  0.48843112370004926,\n",
       "  0.4965342184964956,\n",
       "  0.5062969833085817,\n",
       "  0.5138143122190378]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(mod1.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
